{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github//jayralencar/pictoBERT/blob/main/Training_PictoBERT.ipynb \"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/jayralencar/pictoBERT/blob/main/Training_PictoBERT.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "qV1EjzcqY1Fa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N5dkLkCkiwd"
      },
      "source": [
        "# Training PictoBERT\n",
        "\n",
        "This notebook contains the code for training pictoBERT. As its aim is to illustrate, we use only one version (contextualized) and train in fewer epochs (2). But, if the objective is to replicate the process described in the paper, it can be changed in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__WGnFptY0Kt",
        "outputId": "18d52348-45ab-4da6-e27d-2144c44bcbf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Mar 22 17:43:31 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
            "| N/A   45C    P8    15W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULCkoWcBkhzM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "MODEL_VERSION = \"contextual\"\n",
        "MAX_EPOCHS = 10\n",
        "WARMUP_STEPS = int(MAX_EPOCHS * 0.15)\n",
        "BATCH_SIZE = 112 # batch size tunned for Tesla T4 GPU\n",
        "LEARNING_RATE = 1e-04\n",
        "NUM_WORKERS = 4\n",
        "GPUS = torch.cuda.device_count()\n",
        "PRECISION = 16 if torch.cuda.device_count() > 0 else 32\n",
        "MLM_PROBABILITY= 0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q94pHWXulqWO",
        "outputId": "71986ca3-bb8d-4e5c-ecfa-6c2e39cbe20f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch_lightning==1.2.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/0c/e2d52147ac12a77ee4e7fd7deb4b5f334cfb335af9133a0f2780c8bb9a2c/pytorch_lightning-1.2.10-py3-none-any.whl (841kB)\n",
            "\u001b[K     |████████████████████████████████| 849kB 32.0MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting future>=0.17.1 (from pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 69.1MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==1.2.10) (1.21.5)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==1.2.10) (21.3)\n",
            "Collecting tensorboard!=2.5.0,>=2.2.0 (from pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/fd/67c61276de025801cfa8a1b9af2d7c577e7f27c17b6bff2baca20bf03543/tensorboard-2.8.0-py3-none-any.whl (5.8MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8MB 32.9MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: PyYAML!=5.4.*,>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==1.2.10) (6.0)\n",
            "Collecting tqdm>=4.41.0 (from pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/1c/93a2b77b97cdba15a59c3d2d03e53d3292158d1106d37f579069abd90ece/tqdm-4.63.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 43.4MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting torchmetrics==0.2.0 (from pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/42/d984612cabf005a265aa99c8d4ab2958e37b753aafb12f31c81df38751c8/torchmetrics-0.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 73.3MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting fsspec[http]>=0.8.1 (from pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/80/cd21f093faef23c03b9fc1274be7a3bfd63b809d2f06a1cff92e00cacfcc/fsspec-2022.2.0-py3-none-any.whl (134kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 72.2MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==1.2.10) (1.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pytorch_lightning==1.2.10) (3.0.4)\n",
            "Collecting werkzeug>=0.11.15 (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/f3/22afbdb20cc4654b10c98043414a14057cd27fdba9d4ae61cea596000ba2/Werkzeug-2.0.3-py3-none-any.whl (289kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 70.1MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting protobuf>=3.6.0 (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/1c/f18d97fc479b4fb6f72bbb0e41188575362e3bbd31014cf294ef0fdec8bf/protobuf-3.19.4-py2.py3-none-any.whl (162kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 67.8MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (2.22.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (41.0.1)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/68/e8ecfac5dd594b676c23a7f07ea34c197d7d69b3313afdf8ac1b0a9905a2/tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 69.5MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "  Downloading https://files.pythonhosted.org/packages/b1/0e/0636cc1448a7abc444fb1b3a63655e294e0d2d49092dc3de05241be6d43c/google_auth_oauthlib-0.4.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (0.33.4)\n",
            "Collecting absl-py>=0.4 (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/03/e3e19d3faf430ede32e41221b294e37952e06acc96781c417ac25d4a0324/absl_py-1.0.0-py3-none-any.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 69.0MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f9/802efd84988bffd9f644c03b6e66fde8e76c3aa33db4279ddd11c5d61f4b/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9MB 67.7MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting grpcio>=1.24.3 (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/02/1ca896d0cc3b528a35000a55e7237af92db446acac83664ada7a25a2fe7d/grpcio-1.44.0-cp37-cp37m-manylinux2010_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 63.2MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/d4/2c7f83915d437736996b2674300c6c4b578a6f897f34e40f5c04db146719/Markdown-3.3.6-py3-none-any.whl (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 44.4MB/s ta 0:00:01\n",
            "\u001b[?25hCollecting google-auth<3,>=1.6.3 (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/6c/e784c6883689fae9d1c5f82d995ddc82c284daa514edd5ba67ea38d88341/google_auth-2.6.2-py2.py3-none-any.whl (156kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 71.6MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting aiohttp; extra == \"http\" (from fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/fe/80c594d62a7ff07730fd2cfc3a058498087436d8c938243e0610d1928f0e/aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 65.4MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->pytorch_lightning==1.2.10) (4.1.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (2021.10.8)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.24.2)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/bb/5deac77a9af870143c684ab46a7934038a53eb4aa975bc0687ed6ca2c610/requests_oauthlib-1.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (4.8.2)\n",
            "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\" (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "  Downloading https://files.pythonhosted.org/packages/30/ab/8fd9e88e6fa5ec41afca995938bbefb72195278e0cfc5bd76a4f29b23fb2/rsa-4.8-py3-none-any.whl\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "  Downloading https://files.pythonhosted.org/packages/19/99/ace1769546388976b45e93445bb04c6df95e96363f03fbb56f916da5ebde/cachetools-5.0.0-py3-none-any.whl\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 74.1MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/c1/8991e7c5385b897b8c020cdaad718c5b087a6626d1d11a23e1ea87e325a7/async_timeout-4.0.2-py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/7f/af3ecdf87e8e41da7b133f1d61f82745f8c862bdade3b56addee3ad23956/yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 66.9MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting charset-normalizer<3.0,>=2.0 (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n",
            "  Downloading https://files.pythonhosted.org/packages/06/b3/24afc8868eba069a7f03650ac750a778862dc34941a4bebeb58706715726/charset_normalizer-2.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (21.4.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/ae/e4437fe5b5ba0fbccdaf8ecde8e3b6e8903793ca638c4706d034c0969ce1/frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 70.7MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/a7/71c253cdb8a1528802bac7503bf82fe674367e4055b09c28846fdfa4ab90/multidict-6.0.2.tar.gz (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 31.2MB/s eta 0:00:01\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting asynctest==0.13.0; python_version < \"3.8\" (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n",
            "  Downloading https://files.pythonhosted.org/packages/e8/b6/8d17e169d577ca7678b11cd0d3ceebb0a6089a7f4a2de4b945fe4b1c86db/asynctest-0.13.0-py3-none-any.whl\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/87/fe94898f2d44a93a35d5aa74671ed28094d80753a1113d68b799fab6dc22/aiosignal-1.2.0-py3-none-any.whl\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/46/5ee2475e1b46a26ca0fa10d3c1d479577fde6ee289f8c6aa6d7ec33e31fd/oauthlib-3.2.0-py3-none-any.whl (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 71.7MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (3.7.0)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 42.9MB/s eta 0:00:01\n",
            "\u001b[?25hBuilding wheels for collected packages: multidict\n",
            "  Building wheel for multidict (PEP 517) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e7/67/fd/4e3843a89ae0e233d79452f8f04e45814f350173a99f5addc9\n",
            "Successfully built multidict\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built future\n",
            "Installing collected packages: future, werkzeug, protobuf, tensorboard-plugin-wit, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, absl-py, tensorboard-data-server, grpcio, markdown, tensorboard, tqdm, torchmetrics, async-timeout, multidict, yarl, charset-normalizer, frozenlist, asynctest, aiosignal, aiohttp, fsspec, pytorch-lightning\n",
            "  Found existing installation: tqdm 4.32.1\n",
            "    Uninstalling tqdm-4.32.1:\n",
            "      Successfully uninstalled tqdm-4.32.1\n",
            "Successfully installed absl-py-1.0.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 cachetools-5.0.0 charset-normalizer-2.0.12 frozenlist-1.3.0 fsspec-2022.2.0 future-0.18.2 google-auth-2.6.2 google-auth-oauthlib-0.4.6 grpcio-1.44.0 markdown-3.3.6 multidict-6.0.2 oauthlib-3.2.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch-lightning-1.2.10 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torchmetrics-0.2.0 tqdm-4.63.0 werkzeug-2.0.3 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_lightning==1.2.10 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-WVtWf4l6p-"
      },
      "source": [
        "## Loading tokenizer\n",
        "\n",
        "Its necessary to load the trained tokenizer to be used in data collation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joG8vGEGl8We",
        "outputId": "4fd02c21-1d06-4551-902c-ef13594efce3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-2g-GCxjBwESqDn3JByAJABU9Dkuqy0m\n",
            "To: /root/capsule/childes_all_new.json\n",
            "100%|████████████████████████████████████████| 332k/332k [00:00<00:00, 10.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!wget http://jayr.clubedosgeeks.com.br/pictobert/childes_all_new.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0KITnM9mVbk"
      },
      "outputs": [],
      "source": [
        "TOKENIZER_PATH = \"./childes_all_new.json\" # you can change this path to use your custom tokenizer\n",
        "\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "loaded_tokenizer = PreTrainedTokenizerFast(tokenizer_file=TOKENIZER_PATH)\n",
        "loaded_tokenizer.pad_token = \"[PAD]\"\n",
        "loaded_tokenizer.sep_token = \"[SEP]\"\n",
        "loaded_tokenizer.mask_token = \"[MASK]\"\n",
        "loaded_tokenizer.cls_token = \"[CLS]\"\n",
        "loaded_tokenizer.unk_token = \"[UNK]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8TdA0K-mWOa"
      },
      "source": [
        "## Loading datasets\n",
        "\n",
        "We load the dataset split in the dataset preparation step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3awQq_znhKS",
        "outputId": "4e680618-f356-4c3e-8599-87015682535b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Mn2eIeSCBLk8tpU2NwNQblooFcqSbjmh\n",
            "To: /root/capsule/train_childes_all.pt\n",
            "100%|████████████████████████████████████████| 247M/247M [00:03<00:00, 81.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qEX2zVxX8xFbBfY4mLSf0qG4wgkHFggD\n",
            "To: /root/capsule/test_childes_all.pt\n",
            "100%|██████████████████████████████████████| 2.52M/2.52M [00:00<00:00, 40.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BwPXeP3lKQk-orKAq1bs2C7hg-B1D6QG\n",
            "To: /root/capsule/val_childes_all.pt\n",
            "100%|██████████████████████████████████████| 2.52M/2.52M [00:00<00:00, 45.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!wget http://jayr.clubedosgeeks.com.br/pictobert/train_childes_all.pt\n",
        "!wget http://jayr.clubedosgeeks.com.br/pictobert/test_childes_all.pt\n",
        "!wget http://jayr.clubedosgeeks.com.br/pictobert/val_childes_all.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qsc5YzJZn1gm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, Subset\n",
        "from torch import tensor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, examples):\n",
        "    self.input_ids = examples['input_ids']\n",
        "    self.attention_mask = examples['attention_mask']\n",
        "    self.special_tokens_mask = examples['special_tokens_mask']\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    input_ids = tensor(self.input_ids[idx])\n",
        "    attention_mask = tensor(self.attention_mask[idx])\n",
        "    special_tokens_mask = tensor(self.special_tokens_mask[idx])\n",
        "\n",
        "    return {\n",
        "      \"input_ids\":input_ids, \n",
        "      \"attention_mask\":attention_mask, \n",
        "      \"special_tokens_mask\":special_tokens_mask\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVU4dkIsn6r6"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "tds = pickle.load(open('./train_childes_all.pt','rb'))\n",
        "train_dataset = MyDataset(tds)\n",
        "\n",
        "vds = pickle.load(open('./val_childes_all.pt','rb'))\n",
        "val_dataset = MyDataset(vds)\n",
        "\n",
        "tsds = pickle.load(open('./test_childes_all.pt','rb'))\n",
        "test_dataset = MyDataset(tsds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGcXeDqzoDVJ"
      },
      "source": [
        "### Data collator\n",
        "\n",
        "Data collation prepare the dataset for training. For masked language modeling it replace 15% (or the value defined in MLM_PROBABILITY) of each batch tokens with a [MASK] token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBh-kEdDoV7m"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=loaded_tokenizer, mlm_probability=MLM_PROBABILITY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVOno07Sof7G"
      },
      "source": [
        "### Data loaders\n",
        "\n",
        "The dataloaders split the data in batchs and apply collation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYx916tmoojK"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=data_collator,\n",
        "    drop_last = True,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=data_collator,\n",
        "    drop_last = True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    collate_fn=data_collator,\n",
        "    pin_memory=True,\n",
        "    drop_last = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufPDrKzaoyaE"
      },
      "source": [
        "## Defining optmizer\n",
        "\n",
        "BERT uses a Adam Weigth Decay Optimizer. The code below was extracted from [here](https://github.com/jcyk/BERT/blob/88982eb2d8fdfb8984a93df2aa00de07f63af82d/adam.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqLW2svAo8We"
      },
      "source": [
        "## Defining Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlReHaTCo-kd"
      },
      "outputs": [],
      "source": [
        "from argparse import ArgumentParser\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.metrics.functional import accuracy\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from transformers import get_polynomial_decay_schedule_with_warmup\n",
        "from transformers import AdamW\n",
        "\n",
        "from transformers import BertLMHeadModel\n",
        "from transformers import BertForMaskedLM\n",
        "\n",
        "class LitBertClassifier(pl.LightningModule):\n",
        "    def __init__(self, pretrained_model_name='bert-large-uncased'):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.lr = LEARNING_RATE\n",
        "        self.train_dataset = train_dataset\n",
        "        self.bert = BertForMaskedLM.from_pretrained(pretrained_model_name)\n",
        "      \n",
        "    \n",
        "    def freeze_to(self, layers):\n",
        "      for param in self.bert.bert.encoder.layer[:layers].parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        if labels == None:\n",
        "            return self.bert(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "            )    \n",
        "        return self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels = labels\n",
        "        )\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self._shared_step(batch, batch_idx)\n",
        "        loss = outputs[0]\n",
        "\n",
        "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True,)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def train_dataloader(self):\n",
        "      return DataLoader(self.train_dataset,batch_size=self.batch_size,num_workers=NUM_WORKERS,pin_memory=True,collate_fn=data_collator)\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        with torch.no_grad():\n",
        "          result = self._shared_step(batch, batch_idx)\n",
        "          loss = result[0].detach()\n",
        "\n",
        "          return {\n",
        "              \"val_loss\":loss\n",
        "          }\n",
        "    \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        val_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "        self.log(\"val_loss\", val_loss, on_epoch=True, prog_bar=True,)\n",
        "    \n",
        "    \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        with torch.no_grad():\n",
        "          result = self._shared_step(batch, batch_idx)\n",
        "          loss = result[0].detach()\n",
        "          perplexity = torch.exp(loss)\n",
        "          self.log(\"test_ppl\", perplexity, on_epoch=True, prog_bar=True,)\n",
        "          self.log(\"test_loss\", loss, on_epoch=True, prog_bar=True,)\n",
        "\n",
        "          return {\n",
        "              \"test_ppl\":perplexity,\n",
        "              \"test_loss\":loss\n",
        "          }\n",
        "    \n",
        "    def _shared_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        outputs = self.forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      optimizer = AdamW(self.parameters(), lr=self.lr,betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\n",
        "      scheduler = {\n",
        "          'scheduler': get_polynomial_decay_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS,num_training_steps=MAX_EPOCHS,lr_end=1e-08),\n",
        "          # 'scheduler': get_linear_schedule_with_warmup(optimizer,num_warmup_steps=WARMUP_STEPS,num_training_steps=MAX_EPOCHS,last_epoch=-1),\n",
        "          'name': 'lr'\n",
        "      }\n",
        "      return [optimizer],[scheduler]\n",
        "\n",
        "    def backward(self, loss, optimizer, idx):\n",
        "        loss.backward()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0-C7lwPuXPg"
      },
      "source": [
        "## Logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M-ecVPcuYcl"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import loggers as pl_loggers\n",
        "\n",
        "tb_logger = pl_loggers.TensorBoardLogger(\"./logs\",name=MODEL_VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zwcsQxtugne"
      },
      "source": [
        "## Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsXFtnSxuiDt"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=\"./checkpoints\",\n",
        "    filename='bert-large-{epoch:02d}-{val_loss:.2f}',\n",
        "    mode='min',\n",
        "    save_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13LXU-Soun71"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3osuWhPFupBD",
        "outputId": "da8b85db-2215-498e-9c61-44c8f4f4ac81"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Using native 16bit precision.\n"
          ]
        }
      ],
      "source": [
        "trainer = pl.Trainer(\n",
        "    accelerator='ddp',\n",
        "    max_epochs=MAX_EPOCHS,\n",
        "    logger=tb_logger,\n",
        "    gpus=GPUS,\n",
        "    callbacks=[checkpoint_callback],\n",
        "    precision=PRECISION,\n",
        "    auto_scale_batch_size=\"binsearch\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMy2fXEPr5Wx"
      },
      "source": [
        "## Load model\n",
        "\n",
        "We use only one model for exemplifying, but both are downloaded in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR9gMvgzw0Og",
        "outputId": "0d0ad1e5-b3c8-404d-f688-fb9d5e500e5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AurGqnaxZ6JMl91BM9khScOlxGmzJ23z\n",
            "To: /root/capsule/pictobert-large-contextual.zip\n",
            "100%|███████████████████████████████████████| 1.18G/1.18G [00:07<00:00, 148MB/s]\n"
          ]
        }
      ],
      "source": [
        "!wget http://jayr.clubedosgeeks.com.br/pictobert/pictobert-large-contextual.zip\n",
        "!wget http://jayr.clubedosgeeks.com.br/pictobert/pictobert-large-gloss.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2VQMnAP4TtH",
        "outputId": "8303a434-fcdd-4dce-d17e-209fa4a28ce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ./pictobert-large-contextual.zip\n",
            "Created by ZIP Extractor v4.31 on 7-May-2021 (https://zipextractor.app)\n",
            "replace contextual/pytorch_model.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ]
        }
      ],
      "source": [
        "!unzip ./pictobert-large-contextual.zip -d contextual\n",
        "!unzip ./pictobert-large-gloss.zip -d contextual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BGMN4o4r7VC"
      },
      "outputs": [],
      "source": [
        "model = LitBertClassifier(MODEL_VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n92kGj642Hc"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "41cb0dc9b2674fef857c01ae25220589",
            "3ac8043377ed4a17a73ee5fcf7430782",
            "c90e71429b864eb2b77a52f0c9607d1d",
            "c007752893e7420da20406bae898a88c",
            "b274e54bbbb948239d9eaeac1840a139",
            "6dcbf4ad3f4b4347ac58e7d155aed5fb",
            "b8826bd457ae4fef88aab08173e73b9f",
            "1936ce72f3c441358fae635df0f54a4e",
            "83cb913a538e4853824525057c40b54f",
            "deb0bfd9caba4974b53ec4ede2c82aec",
            "0ccc362f935846a2afac45a2ff772e72",
            "93b9c4538b8d4e3cb46ad6bcfdb7be30",
            "3ad42ac2aa72465e9c6bc023314e282a",
            "4af45b2ac7434519908a427eaac54094",
            "5b89ae44c91344779f17618adb89b131",
            "2c3529a7628547c98e2b32d18885ab87",
            "",
            "6b54c74b4f5341bcb8bb5b1d561c4d36"
          ]
        },
        "id": "b-RHGbbR4zpR",
        "outputId": "742147e0-3730-413b-d995-194278e4089b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "\n",
            "  | Name | Type            | Params\n",
            "-----------------------------------------\n",
            "0 | bert | BertForMaskedLM | 317 M \n",
            "-----------------------------------------\n",
            "317 M     Trainable params\n",
            "0         Non-trainable params\n",
            "317 M     Total params\n",
            "1,271.248 Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b54c74b4f5341bcb8bb5b1d561c4d36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Saving latest checkpoint...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.fit(model, train_dataloader,val_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VihTmjvY0Li"
      },
      "outputs": [],
      "source": [
        "#trainer.tune(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLJ--68P5kVC"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuS919rG5pHa",
        "outputId": "53582b55-edad-4b7f-b40d-7d6390b6e5eb",
        "colab": {
          "referenced_widgets": [
            "88adbed68d0c423b85ba9bbbef9cd9cc"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88adbed68d0c423b85ba9bbbef9cd9cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_loss': 334.57952880859375, 'test_ppl': inf}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'test_ppl': inf, 'test_loss': 334.57952880859375}]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.test(model,test_dataloaders=test_dataloader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Training PictoBERT.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ccc362f935846a2afac45a2ff772e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "Epoch 0:   0%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4af45b2ac7434519908a427eaac54094",
            "max": 29559,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ad42ac2aa72465e9c6bc023314e282a",
            "value": 60
          },
          "model_module_version": "1.5.0"
        },
        "1936ce72f3c441358fae635df0f54a4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "2c3529a7628547c98e2b32d18885ab87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "3ac8043377ed4a17a73ee5fcf7430782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          },
          "model_module_version": "1.2.0"
        },
        "3ad42ac2aa72465e9c6bc023314e282a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          },
          "model_module_version": "1.5.0"
        },
        "41cb0dc9b2674fef857c01ae25220589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c90e71429b864eb2b77a52f0c9607d1d",
              "IPY_MODEL_c007752893e7420da20406bae898a88c"
            ],
            "layout": "IPY_MODEL_3ac8043377ed4a17a73ee5fcf7430782"
          },
          "model_module_version": "1.5.0"
        },
        "4af45b2ac7434519908a427eaac54094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "5b89ae44c91344779f17618adb89b131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          },
          "model_module_version": "1.5.0"
        },
        "6dcbf4ad3f4b4347ac58e7d155aed5fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "83cb913a538e4853824525057c40b54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ccc362f935846a2afac45a2ff772e72",
              "IPY_MODEL_93b9c4538b8d4e3cb46ad6bcfdb7be30"
            ],
            "layout": "IPY_MODEL_deb0bfd9caba4974b53ec4ede2c82aec"
          },
          "model_module_version": "1.5.0"
        },
        "93b9c4538b8d4e3cb46ad6bcfdb7be30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c3529a7628547c98e2b32d18885ab87",
            "placeholder": "​",
            "style": "IPY_MODEL_5b89ae44c91344779f17618adb89b131",
            "value": " 60/29559 [03:14&lt;26:33:19,  3.24s/it, loss=32.8, v_num=0, val_loss=291.0, train_loss_step=29.60]"
          },
          "model_module_version": "1.5.0"
        },
        "b274e54bbbb948239d9eaeac1840a139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          },
          "model_module_version": "1.5.0"
        },
        "b8826bd457ae4fef88aab08173e73b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          },
          "model_module_version": "1.5.0"
        },
        "c007752893e7420da20406bae898a88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1936ce72f3c441358fae635df0f54a4e",
            "placeholder": "​",
            "style": "IPY_MODEL_b8826bd457ae4fef88aab08173e73b9f",
            "value": " 0/2 [00:02&lt;?, ?it/s]"
          },
          "model_module_version": "1.5.0"
        },
        "c90e71429b864eb2b77a52f0c9607d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "Validation sanity check:   0%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dcbf4ad3f4b4347ac58e7d155aed5fb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b274e54bbbb948239d9eaeac1840a139",
            "value": 0
          },
          "model_module_version": "1.5.0"
        },
        "deb0bfd9caba4974b53ec4ede2c82aec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}