{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building SEM Childes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHft9TQBwmG"
      },
      "source": [
        "# SemCHILDES construction\n",
        "\n",
        "As an initial effort to construct SemCHILDES, I use an automatic word sense disambiguation to annotate the CHILDES corpus with word senses. As future work, I intend to manually annotate part of the corpus and then evaluate the performance of different algorithms, approaches, and combination of them in the annotated data. The best approach will be used to annotate the entire corpus.\n",
        "\n",
        "Used tool: PySupWSDPocket - https://github.com/rodriguesfas/PySupWSDPocket\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "046SWOBoZ6h9"
      },
      "source": [
        "## PySupWSDPocket\n",
        "\n",
        "PySupWSDPocket is a python lib for the [SupWSD Pocket](https://supwsd.net/supwsd/pocket.jsp). SupWSD is a supervised model for Word Sense Disambiguation.\n",
        "\n",
        "We install it from github to get the latest version.\n",
        "\n",
        "https://drive.google.com/file/d/1hEMlbToLL4xN7HJhPtebMbKYeethWmha/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKtraXRNBrd2",
        "outputId": "7ef126b3-95a1-4608-8311-1772c6dc6953"
      },
      "source": [
        "!pip install git+https://github.com/rodriguesfas/PySupWSDPocket.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rodriguesfas/PySupWSDPocket.git\n",
            "  Cloning https://github.com/rodriguesfas/PySupWSDPocket.git to /tmp/pip-req-build-wt33a1rh\n",
            "  Running command git clone -q https://github.com/rodriguesfas/PySupWSDPocket.git /tmp/pip-req-build-wt33a1rh\n",
            "Building wheels for collected packages: pysupwsdpocket\n",
            "  Building wheel for pysupwsdpocket (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysupwsdpocket: filename=pysupwsdpocket-0.0.9-cp37-none-any.whl size=1443874 sha256=5de6034d64343a6dd7638f5df8a2bcd77cd9c7eec29e1325666e183e632ef102\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-of40il45/wheels/60/71/8d/80f8c9ddf9fd2b65d10328afb6d580cfd83e4fbbc690cfb4dc\n",
            "Successfully built pysupwsdpocket\n",
            "Installing collected packages: pysupwsdpocket\n",
            "Successfully installed pysupwsdpocket-0.0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew8ZdgXqaQN7"
      },
      "source": [
        "PySupWSDPocket requires downloading its ~2GB model available on https://supwsd.net/supwsd/downloads.jsp#supwsd_pocket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48gIwr7kahDI",
        "outputId": "1f44c4f9-e1ca-4886-82ab-e58ab2d204a2"
      },
      "source": [
        "!mkdir pysupwsdpocket_models\n",
        "!gdown  https://drive.google.com/uc?id=1hEMlbToLL4xN7HJhPtebMbKYeethWmha  -O=\"/content/pysupwsdpocket_models/en.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘pysupwsdpocket_models’: File exists\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hEMlbToLL4xN7HJhPtebMbKYeethWmha\n",
            "To: /content/pysupwsdpocket_models/en.zip\n",
            "1.80GB [00:20, 89.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpE4JyOybbRk"
      },
      "source": [
        "from pysupwsdpocket import PySupWSDPocket\n",
        "nlp = PySupWSDPocket(lang='en', model='semcor_omsti', model_path=\"./pysupwsdpocket_models/\")    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMbbURW6b7xM"
      },
      "source": [
        "## CHILDES\n",
        "\n",
        "The Child Language Data Exchange System (CHILDES) is a corpus established in 1984 by Brian MacWhinney and Catherine Snow to serve as a central repository for data of first language acquisition[¹](https://en.wikipedia.org/wiki/CHILDES). It counts with a list of different corpora from many languages that can be downloaded in XML or CHA format.\n",
        "\n",
        "In this notebook we download only one corpus, but SemCHILDES is composed by the entire American English CHILDES."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwErSnaqdQG-",
        "outputId": "1a4501e7-774c-4db0-e44f-f5c4b68174c4"
      },
      "source": [
        "!mkdir corpora\n",
        "!wget https://childes.talkbank.org/data-xml/Eng-NA/MacWhinney.zip -O /content/corpora/MacWhinney.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-09 16:28:46--  https://childes.talkbank.org/data-xml/Eng-NA/MacWhinney.zip\n",
            "Resolving childes.talkbank.org (childes.talkbank.org)... 128.2.24.68\n",
            "Connecting to childes.talkbank.org (childes.talkbank.org)|128.2.24.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8844400 (8.4M) [application/zip]\n",
            "Saving to: ‘/content/corpora/MacWhinney.zip’\n",
            "\n",
            "/content/corpora/Ma 100%[===================>]   8.43M  18.6MB/s    in 0.5s    \n",
            "\n",
            "2021-04-09 16:28:47 (18.6 MB/s) - ‘/content/corpora/MacWhinney.zip’ saved [8844400/8844400]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBCE-7GaeE4s",
        "outputId": "cbf327d2-edf1-4cfc-c0b6-13f0943c638d"
      },
      "source": [
        "!unzip /content/corpora/MacWhinney.zip -d corpora"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/corpora/MacWhinney.zip\n",
            "  inflating: corpora/MacWhinney/010123d.xml  \n",
            "  inflating: corpora/MacWhinney/050820a.xml  \n",
            "  inflating: corpora/MacWhinney/010204b.xml  \n",
            "  inflating: corpora/MacWhinney/000818a.xml  \n",
            "  inflating: corpora/MacWhinney/021109.xml  \n",
            "  inflating: corpora/MacWhinney/030001b.xml  \n",
            "  inflating: corpora/MacWhinney/041125b.xml  \n",
            "  inflating: corpora/MacWhinney/030105c.xml  \n",
            "  inflating: corpora/MacWhinney/040315.xml  \n",
            "  inflating: corpora/MacWhinney/060027c.xml  \n",
            "  inflating: corpora/MacWhinney/051016d.xml  \n",
            "  inflating: corpora/MacWhinney/020627.xml  \n",
            "  inflating: corpora/MacWhinney/010114d.xml  \n",
            "  inflating: corpora/MacWhinney/040920c.xml  \n",
            "  inflating: corpora/MacWhinney/030818.xml  \n",
            "  inflating: corpora/MacWhinney/040920b.xml  \n",
            "  inflating: corpora/MacWhinney/050420a.xml  \n",
            "  inflating: corpora/MacWhinney/060530c.xml  \n",
            "  inflating: corpora/MacWhinney/030105d.xml  \n",
            "  inflating: corpora/MacWhinney/040508d.xml  \n",
            "  inflating: corpora/MacWhinney/060530b.xml  \n",
            "  inflating: corpora/MacWhinney/030105b.xml  \n",
            "  inflating: corpora/MacWhinney/061017b.xml  \n",
            "  inflating: corpora/MacWhinney/030625a.xml  \n",
            "  inflating: corpora/MacWhinney/060906d.xml  \n",
            "  inflating: corpora/MacWhinney/050622a.xml  \n",
            "  inflating: corpora/MacWhinney/030329a.xml  \n",
            "  inflating: corpora/MacWhinney/030628.xml  \n",
            "  inflating: corpora/MacWhinney/060922b.xml  \n",
            "  inflating: corpora/MacWhinney/050820d.xml  \n",
            "  inflating: corpora/MacWhinney/040316a.xml  \n",
            "  inflating: corpora/MacWhinney/030602.xml  \n",
            "  inflating: corpora/MacWhinney/020617a.xml  \n",
            "  inflating: corpora/MacWhinney/060027b.xml  \n",
            "  inflating: corpora/MacWhinney/030426a.xml  \n",
            "  inflating: corpora/MacWhinney/051117d.xml  \n",
            "  inflating: corpora/MacWhinney/060422c.xml  \n",
            "  inflating: corpora/MacWhinney/030202.xml  \n",
            "  inflating: corpora/MacWhinney/050713d.xml  \n",
            "  inflating: corpora/MacWhinney/050120b.xml  \n",
            "  inflating: corpora/MacWhinney/010114a.xml  \n",
            "  inflating: corpora/MacWhinney/041027a.xml  \n",
            "  inflating: corpora/MacWhinney/030018b.xml  \n",
            "  inflating: corpora/MacWhinney/060123a.xml  \n",
            "  inflating: corpora/MacWhinney/030522.xml  \n",
            "  inflating: corpora/MacWhinney/040101.xml  \n",
            "  inflating: corpora/MacWhinney/060714d.xml  \n",
            "  inflating: corpora/MacWhinney/060310e.xml  \n",
            "  inflating: corpora/MacWhinney/030428.xml  \n",
            "  inflating: corpora/MacWhinney/060211a2.xml  \n",
            "  inflating: corpora/MacWhinney/020514b.xml  \n",
            "  inflating: corpora/MacWhinney/020617b.xml  \n",
            "  inflating: corpora/MacWhinney/031001.xml  \n",
            "  inflating: corpora/MacWhinney/050713a.xml  \n",
            "  inflating: corpora/MacWhinney/050309d.xml  \n",
            "  inflating: corpora/MacWhinney/070018d.xml  \n",
            "  inflating: corpora/MacWhinney/061119a.xml  \n",
            "  inflating: corpora/MacWhinney/030327.xml  \n",
            "  inflating: corpora/MacWhinney/060002b.xml  \n",
            "  inflating: corpora/MacWhinney/01diary.xml  \n",
            "  inflating: corpora/MacWhinney/061017d.xml  \n",
            "  inflating: corpora/MacWhinney/020608.xml  \n",
            "  inflating: corpora/MacWhinney/030105a.xml  \n",
            "  inflating: corpora/MacWhinney/061017a.xml  \n",
            "  inflating: corpora/MacWhinney/041027b.xml  \n",
            "  inflating: corpora/MacWhinney/030526b.xml  \n",
            "  inflating: corpora/MacWhinney/050713b.xml  \n",
            "  inflating: corpora/MacWhinney/040223.xml  \n",
            "  inflating: corpora/MacWhinney/000203d.xml  \n",
            "  inflating: corpora/MacWhinney/000917d.xml  \n",
            "  inflating: corpora/MacWhinney/010405d.xml  \n",
            "  inflating: corpora/MacWhinney/021017a.xml  \n",
            "  inflating: corpora/MacWhinney/001111b.xml  \n",
            "  inflating: corpora/MacWhinney/050913a.xml  \n",
            "  inflating: corpora/MacWhinney/020915.xml  \n",
            "  inflating: corpora/MacWhinney/020910.xml  \n",
            "  inflating: corpora/MacWhinney/070503a.xml  \n",
            "  inflating: corpora/MacWhinney/051001b.xml  \n",
            "  inflating: corpora/MacWhinney/050309b.xml  \n",
            "  inflating: corpora/MacWhinney/040920d.xml  \n",
            "  inflating: corpora/MacWhinney/010609.xml  \n",
            "  inflating: corpora/MacWhinney/050520.xml  \n",
            "  inflating: corpora/MacWhinney/040508b.xml  \n",
            "  inflating: corpora/MacWhinney/050713c.xml  \n",
            "  inflating: corpora/MacWhinney/070600d.xml  \n",
            "  inflating: corpora/MacWhinney/021022a.xml  \n",
            "  inflating: corpora/MacWhinney/010405c.xml  \n",
            "  inflating: corpora/MacWhinney/040316c.xml  \n",
            "  inflating: corpora/MacWhinney/030001a.xml  \n",
            "  inflating: corpora/MacWhinney/060922c.xml  \n",
            "  inflating: corpora/MacWhinney/060906c.xml  \n",
            "  inflating: corpora/MacWhinney/061017c.xml  \n",
            "  inflating: corpora/MacWhinney/000917a.xml  \n",
            "  inflating: corpora/MacWhinney/040404d.xml  \n",
            "  inflating: corpora/MacWhinney/070018c.xml  \n",
            "  inflating: corpora/MacWhinney/070318c.xml  \n",
            "  inflating: corpora/MacWhinney/040316b.xml  \n",
            "  inflating: corpora/MacWhinney/010425a.xml  \n",
            "  inflating: corpora/MacWhinney/070318.xml  \n",
            "  inflating: corpora/MacWhinney/010405a.xml  \n",
            "  inflating: corpora/MacWhinney/000623d.xml  \n",
            "  inflating: corpora/MacWhinney/020718c.xml  \n",
            "  inflating: corpora/MacWhinney/030017.xml  \n",
            "  inflating: corpora/MacWhinney/021001d.xml  \n",
            "  inflating: corpora/MacWhinney/021017b.xml  \n",
            "  inflating: corpora/MacWhinney/030805.xml  \n",
            "  inflating: corpora/MacWhinney/021100b.xml  \n",
            "  inflating: corpora/MacWhinney/051001a.xml  \n",
            "  inflating: corpora/MacWhinney/030329b.xml  \n",
            "  inflating: corpora/MacWhinney/050622b.xml  \n",
            "  inflating: corpora/MacWhinney/070600a.xml  \n",
            "  inflating: corpora/MacWhinney/060401.xml  \n",
            "  inflating: corpora/MacWhinney/031021.xml  \n",
            "  inflating: corpora/MacWhinney/051016a.xml  \n",
            "  inflating: corpora/MacWhinney/030328.xml  \n",
            "  inflating: corpora/MacWhinney/060123d.xml  \n",
            "  inflating: corpora/MacWhinney/070518c.xml  \n",
            "  inflating: corpora/MacWhinney/020617e.xml  \n",
            "  inflating: corpora/MacWhinney/040305b.xml  \n",
            "  inflating: corpora/MacWhinney/070702.xml  \n",
            "  inflating: corpora/MacWhinney/050512.xml  \n",
            "  inflating: corpora/MacWhinney/020817d.xml  \n",
            "  inflating: corpora/MacWhinney/070518a.xml  \n",
            "  inflating: corpora/MacWhinney/040008.xml  \n",
            "  inflating: corpora/MacWhinney/060714c.xml  \n",
            "  inflating: corpora/MacWhinney/000614a.xml  \n",
            "  inflating: corpora/MacWhinney/021001a.xml  \n",
            "  inflating: corpora/MacWhinney/021114.xml  \n",
            "  inflating: corpora/MacWhinney/070600c.xml  \n",
            "  inflating: corpora/MacWhinney/010411b.xml  \n",
            "  inflating: corpora/MacWhinney/030213b.xml  \n",
            "  inflating: corpora/MacWhinney/021100a.xml  \n",
            "  inflating: corpora/MacWhinney/010425b.xml  \n",
            "  inflating: corpora/MacWhinney/060807b.xml  \n",
            "  inflating: corpora/MacWhinney/021001c.xml  \n",
            "  inflating: corpora/MacWhinney/030726.xml  \n",
            "  inflating: corpora/MacWhinney/020925.xml  \n",
            "  inflating: corpora/MacWhinney/020805c.xml  \n",
            "  inflating: corpora/MacWhinney/050520b.xml  \n",
            "  inflating: corpora/MacWhinney/060302d.xml  \n",
            "  inflating: corpora/MacWhinney/030426b.xml  \n",
            "  inflating: corpora/MacWhinney/051001c.xml  \n",
            "  inflating: corpora/MacWhinney/070318d.xml  \n",
            "  inflating: corpora/MacWhinney/000203c.xml  \n",
            "  inflating: corpora/MacWhinney/060123c.xml  \n",
            "  inflating: corpora/MacWhinney/030001c.xml  \n",
            "  inflating: corpora/MacWhinney/010009b.xml  \n",
            "  inflating: corpora/MacWhinney/050520a.xml  \n",
            "  inflating: corpora/MacWhinney/000710b.xml  \n",
            "  inflating: corpora/MacWhinney/050120a.xml  \n",
            "  inflating: corpora/MacWhinney/060530a.xml  \n",
            "  inflating: corpora/MacWhinney/031130.xml  \n",
            "  inflating: corpora/MacWhinney/010411a.xml  \n",
            "  inflating: corpora/MacWhinney/051117c.xml  \n",
            "  inflating: corpora/MacWhinney/060222c.xml  \n",
            "  inflating: corpora/MacWhinney/030101.xml  \n",
            "  inflating: corpora/MacWhinney/070018a.xml  \n",
            "  inflating: corpora/MacWhinney/010114b.xml  \n",
            "  inflating: corpora/MacWhinney/041125d.xml  \n",
            "  inflating: corpora/MacWhinney/061119b.xml  \n",
            "  inflating: corpora/MacWhinney/060211b2.xml  \n",
            "  inflating: corpora/MacWhinney/030625b.xml  \n",
            "  inflating: corpora/MacWhinney/030901.xml  \n",
            "  inflating: corpora/MacWhinney/060530d.xml  \n",
            "  inflating: corpora/MacWhinney/000827a.xml  \n",
            "  inflating: corpora/MacWhinney/001111a.xml  \n",
            "  inflating: corpora/MacWhinney/050820b.xml  \n",
            "  inflating: corpora/MacWhinney/030804.xml  \n",
            "  inflating: corpora/MacWhinney/030315d.xml  \n",
            "  inflating: corpora/MacWhinney/010123b.xml  \n",
            "  inflating: corpora/MacWhinney/030803a.xml  \n",
            "  inflating: corpora/MacWhinney/060328.xml  \n",
            "  inflating: corpora/MacWhinney/000623c.xml  \n",
            "  inflating: corpora/MacWhinney/030526a.xml  \n",
            "  inflating: corpora/MacWhinney/060422b.xml  \n",
            "  inflating: corpora/MacWhinney/060701b.xml  \n",
            "  inflating: corpora/MacWhinney/000827d.xml  \n",
            "  inflating: corpora/MacWhinney/020827b.xml  \n",
            "  inflating: corpora/MacWhinney/060323b.xml  \n",
            "  inflating: corpora/MacWhinney/030221.xml  \n",
            "  inflating: corpora/MacWhinney/040204.xml  \n",
            "  inflating: corpora/MacWhinney/050520c.xml  \n",
            "  inflating: corpora/MacWhinney/010405b.xml  \n",
            "  inflating: corpora/MacWhinney/000614c.xml  \n",
            "  inflating: corpora/MacWhinney/050913c.xml  \n",
            "  inflating: corpora/MacWhinney/021022b.xml  \n",
            "  inflating: corpora/MacWhinney/060211a1.xml  \n",
            "  inflating: corpora/MacWhinney/070518b.xml  \n",
            "  inflating: corpora/MacWhinney/060211b1.xml  \n",
            "  inflating: corpora/MacWhinney/060406a1.xml  \n",
            "  inflating: corpora/MacWhinney/070518d.xml  \n",
            "  inflating: corpora/MacWhinney/040601b.xml  \n",
            "  inflating: corpora/MacWhinney/070503b.xml  \n",
            "  inflating: corpora/MacWhinney/050420c.xml  \n",
            "  inflating: corpora/MacWhinney/041125a.xml  \n",
            "  inflating: corpora/MacWhinney/030720.xml  \n",
            "  inflating: corpora/MacWhinney/040800d.xml  \n",
            "  inflating: corpora/MacWhinney/030403b.xml  \n",
            "  inflating: corpora/MacWhinney/060422d.xml  \n",
            "  inflating: corpora/MacWhinney/040305a.xml  \n",
            "  inflating: corpora/MacWhinney/030315c.xml  \n",
            "  inflating: corpora/MacWhinney/070600b.xml  \n",
            "  inflating: corpora/MacWhinney/010204c.xml  \n",
            "  inflating: corpora/MacWhinney/000623a.xml  \n",
            "  inflating: corpora/MacWhinney/010123a.xml  \n",
            "  inflating: corpora/MacWhinney/000818d.xml  \n",
            "  inflating: corpora/MacWhinney/070722.xml  \n",
            "  inflating: corpora/MacWhinney/060406b2.xml  \n",
            "  inflating: corpora/MacWhinney/020817c.xml  \n",
            "  inflating: corpora/MacWhinney/021101.xml  \n",
            "  inflating: corpora/MacWhinney/060807d.xml  \n",
            "  inflating: corpora/MacWhinney/020923.xml  \n",
            "  inflating: corpora/MacWhinney/070318b.xml  \n",
            "  inflating: corpora/MacWhinney/060906b.xml  \n",
            "  inflating: corpora/MacWhinney/060714b.xml  \n",
            "  inflating: corpora/MacWhinney/040404c.xml  \n",
            "  inflating: corpora/MacWhinney/060002a.xml  \n",
            "  inflating: corpora/MacWhinney/030315a.xml  \n",
            "  inflating: corpora/MacWhinney/030803b.xml  \n",
            "  inflating: corpora/MacWhinney/060310a.xml  \n",
            "  inflating: corpora/MacWhinney/000614d.xml  \n",
            "  inflating: corpora/MacWhinney/010306d.xml  \n",
            "  inflating: corpora/MacWhinney/060422a.xml  \n",
            "  inflating: corpora/MacWhinney/040117a.xml  \n",
            "  inflating: corpora/MacWhinney/060807a.xml  \n",
            "  inflating: corpora/MacWhinney/000710d.xml  \n",
            "  inflating: corpora/MacWhinney/020718a.xml  \n",
            "  inflating: corpora/MacWhinney/010603c.xml  \n",
            "  inflating: corpora/MacWhinney/041125c.xml  \n",
            "  inflating: corpora/MacWhinney/060701c.xml  \n",
            "  inflating: corpora/MacWhinney/020805b.xml  \n",
            "  inflating: corpora/MacWhinney/000818b.xml  \n",
            "  inflating: corpora/MacWhinney/020409.xml  \n",
            "  inflating: corpora/MacWhinney/031114.xml  \n",
            "  inflating: corpora/MacWhinney/050420b.xml  \n",
            "  inflating: corpora/MacWhinney/060807c.xml  \n",
            "  inflating: corpora/MacWhinney/061119d.xml  \n",
            "  inflating: corpora/MacWhinney/060123b.xml  \n",
            "  inflating: corpora/MacWhinney/060310d.xml  \n",
            "  inflating: corpora/MacWhinney/040800a.xml  \n",
            "  inflating: corpora/MacWhinney/050622d.xml  \n",
            "  inflating: corpora/MacWhinney/000917b.xml  \n",
            "  inflating: corpora/MacWhinney/001111c.xml  \n",
            "  inflating: corpora/MacWhinney/030516.xml  \n",
            "  inflating: corpora/MacWhinney/010009c.xml  \n",
            "  inflating: corpora/MacWhinney/020928.xml  \n",
            "  inflating: corpora/MacWhinney/040404b.xml  \n",
            "  inflating: corpora/MacWhinney/010123c.xml  \n",
            "  inflating: corpora/MacWhinney/040800c.xml  \n",
            "  inflating: corpora/MacWhinney/050120d.xml  \n",
            "  inflating: corpora/MacWhinney/021107.xml  \n",
            "  inflating: corpora/MacWhinney/030607.xml  \n",
            "  inflating: corpora/MacWhinney/060406b1.xml  \n",
            "  inflating: corpora/MacWhinney/030403a.xml  \n",
            "  inflating: corpora/MacWhinney/070802.xml  \n",
            "  inflating: corpora/MacWhinney/040920a.xml  \n",
            "  inflating: corpora/MacWhinney/031027.xml  \n",
            "  inflating: corpora/MacWhinney/040201.xml  \n",
            "  inflating: corpora/MacWhinney/060701d.xml  \n",
            "  inflating: corpora/MacWhinney/030018a.xml  \n",
            "  inflating: corpora/MacWhinney/040404a.xml  \n",
            "  inflating: corpora/MacWhinney/051016b.xml  \n",
            "  inflating: corpora/MacWhinney/010523.xml  \n",
            "  inflating: corpora/MacWhinney/050120c.xml  \n",
            "  inflating: corpora/MacWhinney/021017c.xml  \n",
            "  inflating: corpora/MacWhinney/040117b.xml  \n",
            "  inflating: corpora/MacWhinney/061119c.xml  \n",
            "  inflating: corpora/MacWhinney/000623b.xml  \n",
            "  inflating: corpora/MacWhinney/051117a.xml  \n",
            "  inflating: corpora/MacWhinney/040508a.xml  \n",
            "  inflating: corpora/MacWhinney/020827c.xml  \n",
            "  inflating: corpora/MacWhinney/020909b.xml  \n",
            "  inflating: corpora/MacWhinney/030315b.xml  \n",
            "  inflating: corpora/MacWhinney/060310b.xml  \n",
            "  inflating: corpora/MacWhinney/020817a.xml  \n",
            "  inflating: corpora/MacWhinney/030323.xml  \n",
            "  inflating: corpora/MacWhinney/020617d.xml  \n",
            "  inflating: corpora/MacWhinney/060906a.xml  \n",
            "  inflating: corpora/MacWhinney/040019.xml  \n",
            "  inflating: corpora/MacWhinney/050820c.xml  \n",
            "  inflating: corpora/MacWhinney/000917c.xml  \n",
            "  inflating: corpora/MacWhinney/010306b.xml  \n",
            "  inflating: corpora/MacWhinney/051016c.xml  \n",
            "  inflating: corpora/MacWhinney/000203a.xml  \n",
            "  inflating: corpora/MacWhinney/020921.xml  \n",
            "  inflating: corpora/MacWhinney/070018b.xml  \n",
            "  inflating: corpora/MacWhinney/070503d.xml  \n",
            "  inflating: corpora/MacWhinney/030213a.xml  \n",
            "  inflating: corpora/MacWhinney/000614b.xml  \n",
            "  inflating: corpora/MacWhinney/060310c.xml  \n",
            "  inflating: corpora/MacWhinney/060002d.xml  \n",
            "  inflating: corpora/MacWhinney/060002c.xml  \n",
            "  inflating: corpora/MacWhinney/070309b.xml  \n",
            "  inflating: corpora/MacWhinney/020718b.xml  \n",
            "  inflating: corpora/MacWhinney/040601d.xml  \n",
            "  inflating: corpora/MacWhinney/060302a.xml  \n",
            "  inflating: corpora/MacWhinney/010009a.xml  \n",
            "  inflating: corpora/MacWhinney/020617c.xml  \n",
            "  inflating: corpora/MacWhinney/051001d.xml  \n",
            "  inflating: corpora/MacWhinney/031109.xml  \n",
            "  inflating: corpora/MacWhinney/040601c.xml  \n",
            "  inflating: corpora/MacWhinney/030401.xml  \n",
            "  inflating: corpora/MacWhinney/020817b.xml  \n",
            "  inflating: corpora/MacWhinney/070503c.xml  \n",
            "  inflating: corpora/MacWhinney/021001b.xml  \n",
            "  inflating: corpora/MacWhinney/010306a.xml  \n",
            "  inflating: corpora/MacWhinney/000710c.xml  \n",
            "  inflating: corpora/MacWhinney/070309c.xml  \n",
            "  inflating: corpora/MacWhinney/060922a.xml  \n",
            "  inflating: corpora/MacWhinney/030616.xml  \n",
            "  inflating: corpora/MacWhinney/060406a2.xml  \n",
            "  inflating: corpora/MacWhinney/050309c.xml  \n",
            "  inflating: corpora/MacWhinney/060222d.xml  \n",
            "  inflating: corpora/MacWhinney/020805a.xml  \n",
            "  inflating: corpora/MacWhinney/060323a.xml  \n",
            "  inflating: corpora/MacWhinney/070309a.xml  \n",
            "  inflating: corpora/MacWhinney/060714a.xml  \n",
            "  inflating: corpora/MacWhinney/040800b.xml  \n",
            "  inflating: corpora/MacWhinney/020827a.xml  \n",
            "  inflating: corpora/MacWhinney/000827c.xml  \n",
            "  inflating: corpora/MacWhinney/050622c.xml  \n",
            "  inflating: corpora/MacWhinney/020710.xml  \n",
            "  inflating: corpora/MacWhinney/040508c.xml  \n",
            "  inflating: corpora/MacWhinney/020514a.xml  \n",
            "  inflating: corpora/MacWhinney/040316d.xml  \n",
            "  inflating: corpora/MacWhinney/050420d.xml  \n",
            "  inflating: corpora/MacWhinney/000818c.xml  \n",
            "  inflating: corpora/MacWhinney/010204a.xml  \n",
            "  inflating: corpora/MacWhinney/070712.xml  \n",
            "  inflating: corpora/MacWhinney/000710a.xml  \n",
            "  inflating: corpora/MacWhinney/030512.xml  \n",
            "  inflating: corpora/MacWhinney/031128.xml  \n",
            "  inflating: corpora/MacWhinney/020617f.xml  \n",
            "  inflating: corpora/MacWhinney/050309a.xml  \n",
            "  inflating: corpora/MacWhinney/010204d.xml  \n",
            "  inflating: corpora/MacWhinney/060701a.xml  \n",
            "  inflating: corpora/MacWhinney/020909a.xml  \n",
            "  inflating: corpora/MacWhinney/051117b.xml  \n",
            "  inflating: corpora/MacWhinney/020718d.xml  \n",
            "  inflating: corpora/MacWhinney/040601a.xml  \n",
            "  inflating: corpora/MacWhinney/000827b.xml  \n",
            "  inflating: corpora/MacWhinney/010009d.xml  \n",
            "  inflating: corpora/MacWhinney/030704.xml  \n",
            "  inflating: corpora/MacWhinney/000203b.xml  \n",
            "  inflating: corpora/MacWhinney/060922d.xml  \n",
            "  inflating: corpora/MacWhinney/030429.xml  \n",
            "  inflating: corpora/MacWhinney/010114c.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/090826b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080826b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/070809b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/071014b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/081018b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/090000a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080321a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/100719a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/090407a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080719b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/070809c.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/090407b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080215a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080111a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080719a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/090521a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080628a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080628b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080826a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/070809d.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080610a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080027b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/090521b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080027a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/100019a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/070809a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/090210a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/110102b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/071123b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/071101a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/100719b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080801a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/070910d.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/100224b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/100605b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/071014c.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/100019b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/110102a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/081018a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080215b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080801b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080409b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/070910a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/100605a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/090000b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/090210b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080321b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/090826a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080111b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/090030a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/110417a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/100224a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/071014d.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/070910b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080610b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/071123a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/080409a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/070910c.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/071014a.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/071101b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/110417b.xml  \n",
            "  inflating: corpora/MacWhinney/0notrans-late/090030b.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utD4THBMfHA1"
      },
      "source": [
        "### Extract data from CHILDES\n",
        "\n",
        "The data extraction is made by parsing the CHILDES' XML files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qE6mTxLpfjuS",
        "outputId": "19a5fbcb-3889-4869-8a3a-37210ebd0b5c"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "tree = ET.parse(\"/content/corpora/MacWhinney/030018a.xml\")\n",
        "root = tree.getroot()\n",
        "ns = \"{http://www.talkbank.org/ns/talkbank}\"\n",
        "sem_dict = root.attrib\n",
        "sem_dict['file'] = \"/content/corpora/MacWhinney/030018a.xml\"\n",
        "sem_dict['participants'] = []\n",
        "sem_dict['utterances'] = []\n",
        "\n",
        "root.tag"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{http://www.talkbank.org/ns/talkbank}CHAT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRr4FyL5iJhy"
      },
      "source": [
        "#### Find participants\n",
        "\n",
        "This information is important for making restrictions in the future. For example, get sentences by children age."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffacmw7piMAp",
        "outputId": "a0785402-90b2-49dd-918c-9fcb5849561e"
      },
      "source": [
        "for participant in root.find(ns+\"Participants\"):\n",
        "  sem_dict['participants'].append(participant.attrib)\n",
        "sem_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ActivityType': 'toyplay',\n",
              " 'Corpus': 'MacWhinney',\n",
              " 'Date': '1981-01-12',\n",
              " 'DesignType': 'long',\n",
              " 'GroupType': 'TD',\n",
              " 'Lang': 'eng',\n",
              " 'Media': '030018a',\n",
              " 'Mediatypes': 'audio',\n",
              " 'PID': '11312/c-00016502-1',\n",
              " 'Version': '2.16.0',\n",
              " 'file': '/content/corpora/MacWhinney/030018a.xml',\n",
              " 'participants': [{'age': 'P3Y00M18D',\n",
              "   'group': 'TD',\n",
              "   'id': 'CHI',\n",
              "   'language': 'eng',\n",
              "   'name': 'Ross',\n",
              "   'role': 'Target_Child',\n",
              "   'sex': 'male'},\n",
              "  {'age': 'P1Y01M23D',\n",
              "   'id': 'MAR',\n",
              "   'language': 'eng',\n",
              "   'name': 'Mark',\n",
              "   'role': 'Target_Child'},\n",
              "  {'id': 'MOT',\n",
              "   'language': 'eng',\n",
              "   'name': 'Mary',\n",
              "   'role': 'Mother',\n",
              "   'sex': 'female'},\n",
              "  {'id': 'FAT',\n",
              "   'language': 'eng',\n",
              "   'name': 'Brian',\n",
              "   'role': 'Father',\n",
              "   'sex': 'male'}],\n",
              " 'utterances': [],\n",
              " '{http://www.w3.org/2001/XMLSchema-instance}schemaLocation': 'http://www.talkbank.org/ns/talkbank https://talkbank.org/software/talkbank.xsd'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hNky61rklpP"
      },
      "source": [
        "#### Process utterances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lu4HsMVkqhq",
        "outputId": "60fd39d4-78e8-4bc7-c60a-5145908727a2"
      },
      "source": [
        "for u in root.findall(ns+'u'):\n",
        "  utterance_dict = u.attrib\n",
        "  utterance_dict['original_tokens'] = []\n",
        "  tokens = []\n",
        "  for token in u.getchildren():\n",
        "    if token.tag == ns+\"w\":\n",
        "      tags = [a.tag for a in token.getchildren()]\n",
        "      if ns+\"shortening\" in tags:\n",
        "        tokens.append(token.find(ns+'mor').find(ns+\"mw\").find(ns+\"stem\").text)\n",
        "      elif token.text is not None:\n",
        "        tokens.append(token.text)\n",
        "      else:\n",
        "        print(token)\n",
        "    elif token.tag == ns+\"g\": # group of words\n",
        "      token = token.find(ns+'w')\n",
        "      tags = [a.tag for a in token.getchildren()]\n",
        "      if ns+\"shortening\" in tags:\n",
        "        tokens.append(token.find(ns+'mor').find(ns+\"mw\").find(ns+\"stem\").text)\n",
        "      elif token.text is not None:\n",
        "        tokens.append(token.text)\n",
        "      else:\n",
        "        print(token)\n",
        "    elif token.tag == ns+\"t\": # punctuation\n",
        "      if token.attrib['type'] == 'p':\n",
        "        tokens.append(\".\")\n",
        "      elif token.attrib['type'] == 'q':\n",
        "        tokens.append(\"?\")\n",
        "    elif token.tag == ns+\"tagMarker\": #comma\n",
        "      tokens.append(',')\n",
        "  if len(tokens) > 1:\n",
        "    utterance_dict['text'] = \" \".join(tokens)\n",
        "  sem_dict['utterances'].append(utterance_dict)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Element '{http://www.talkbank.org/ns/talkbank}w' at 0x7f48684a6dd0>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-4BK1F8vwbD"
      },
      "source": [
        "#### Parse utterances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7XijIKiHzHqB",
        "outputId": "037ab303-8407-4dd3-8230-653607a80bce"
      },
      "source": [
        "for u in sem_dict['utterances']:\n",
        "  if 'text' in u: # some utterances in CHILDES have just researchers comments or actions like (he screamed)\n",
        "    doc = nlp.wsd(u['text'])\n",
        "    u['wsd_doc'] = []\n",
        "    for token in doc.tokens():\n",
        "      u['wsd_doc'].append(token.__dict__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I got an owie from Titus like Marky got an owie from Titus .\n",
            "why does that cat do that ?\n",
            "because she because her do .\n",
            "because her do ?\n",
            "why does she do it Ross ?\n",
            "because her do .\n",
            "is she mean ?\n",
            "yes .\n",
            "is she mean ?\n",
            "I don't like that cat .\n",
            "why does she do it ?\n",
            "cause she do .\n",
            "let's give her a spanking .\n",
            "okay .\n",
            "no no no .\n",
            "no let's not .\n",
            "let's try to talk to her okay .\n",
            "why ?\n",
            "I'll try to talk to her .\n",
            "owies hurt .\n",
            "I don't like owies .\n",
            "he must have learned that at preschool because we don't use owies we don't talk about owies .\n",
            "this is excellent Ross .\n",
            "what else do you wanna eat ?\n",
            "I wanna eat some more\n",
            "he wants some coq_au_vin juice .\n",
            "no .\n",
            "can I have some chicken off of that ?\n",
            "uh hm .\n",
            "I'll serve you .\n",
            "can I have some more chicken ?\n",
            "more chicken ?\n",
            "yeah .\n",
            "Ross gets a nice piece here mom .\n",
            "uhuh .\n",
            "he does .\n",
            "and momma gets that nice piece .\n",
            "and this big piece back here .\n",
            "thank_you .\n",
            "very good chicken .\n",
            "mhm .\n",
            "thank_you .\n",
            "you're welcome Mother .\n",
            "Mary said it was .\n",
            "no the bird says\n",
            "coo coo .\n",
            "what is the bird doing ?\n",
            "I said\n",
            "the daddy bird flew away and the baby bird flew away and the mommy bird flew away .\n",
            "will you read the bear's Christmas ?\n",
            "mhm .\n",
            "the bear's christmas ?\n",
            "yeah .\n",
            "you mean the Bearinstein Bear's ?\n",
            "I want xxx the bear's christmas .\n",
            "mhm .\n",
            "can I have chicken ?\n",
            "mhm .\n",
            "can I have some more chicken ?\n",
            "yeah you want a good piece ?\n",
            "yeah .\n",
            "here you go .\n",
            "that's a bad piece .\n",
            "wait a second wait a second I'll take the bad part off .\n",
            "there it's all good .\n",
            "but I don't want that .\n",
            "want want the pork ?\n",
            "I don't want that .\n",
            "I just want the other chicken .\n",
            "I just want that good piece .\n",
            "that little piece right here .\n",
            "yeah .\n",
            "okay .\n",
            "I like that piece .\n",
            "mhm .\n",
            "okay sit down and you've got a real good piece on your plate a real good piece .\n",
            "in fact one of the best pieces is the one on your plate .\n",
            "it may be one of the best pieces on the whole chicken .\n",
            "Marky is all pink checked .\n",
            "Marky is awake now .\n",
            "his sentence made more sense than mine .\n",
            "you hurt my peepeesh .\n",
            "I didn't know .\n",
            "you didn't know what you're doing .\n",
            "is that right ?\n",
            "what's happening now ?\n",
            "I'm xxx you .\n",
            "are you going to eat anymore cake ?\n",
            "no .\n",
            "your finished ?\n",
            "yeah .\n",
            "okay we'll clean off your mouth and your hands ?\n",
            "hm no .\n",
            "sticky ?\n",
            "a little sticky ?\n",
            "nope .\n",
            "nope ?\n",
            "that's a little sticky .\n",
            "and your mouth .\n",
            "nope .\n",
            "yep your mouth is dirty .\n",
            "yes it is .\n",
            "yes it is I can see it .\n",
            "it's not so bad but we'll clean it okay .\n",
            "oh Mom that's so nice of you .\n",
            "okay you're finished right Ross ?\n",
            "very good cake mom .\n",
            "excellent frosting .\n",
            "excellent frosting .\n",
            "excellent frosting .\n",
            "super moist .\n",
            "it's excellent frosting because it's homemade .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-7df5b0bb9277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msem_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utterances'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m'text'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# some utterances in CHILDES have just researchers comments or actions like (he screamed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwsd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wsd_doc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pysupwsdpocket/pysupwsdpocket.py\u001b[0m in \u001b[0;36mwsd\u001b[0;34m(self, raw_text)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mjson_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'java'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-jar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJAR_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 411\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    949\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biZoaYASzchG",
        "outputId": "1628c7b6-d102-4581-d2c5-d17aede5cf65"
      },
      "source": [
        "import json\n",
        "f = open(\"sem_childes.json\",'w')\n",
        "f.write(json.dumps(sem_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "198064"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr5FA4xX1B7y"
      },
      "source": [
        "#### Create corpus for BERT input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO7qFl6e4N53",
        "outputId": "5ff4a39d-b699-483f-e0a9-ffd92d1094c1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdsz8UV21Fu5",
        "outputId": "0042d7d9-4620-4ead-ed1d-7fdfd89d5b8e"
      },
      "source": [
        "f = open(\"for_training.txt\",'w')\n",
        "for u in sem_dict['utterances']:\n",
        "  if 'wsd_doc' in u:\n",
        "    print(u['text'])\n",
        "    new_sentence = []\n",
        "    for token in u['wsd_doc']:\n",
        "      if token['word'] in ['me','and','or',',']:\n",
        "          new_sentence.append(token['word'])\n",
        "      elif token['lemma'] in [\"can\",\"a\",\"to\",\"how\",\"what\",'this',\"that\"]:\n",
        "          new_sentence.append(token['lemma'])\n",
        "      elif token['senses'][0]['id'] != 'U':\n",
        "          new_sentence.append(token['senses'][0]['id'])\n",
        "      elif token['pos'] in ['IN','PRP','.','WRB','CC',\"PRP$\",\"DT\"]:\n",
        "          new_sentence.append(token['lemma'])\n",
        "      elif token['pos'] in ['NNP']:\n",
        "          new_sentence.append('proper_noun')\n",
        "      elif token['pos'] in ['NN',\"NNS\"]:\n",
        "          n_token = None\n",
        "          synsets = wn.synsets(token['lemma'],'n')\n",
        "          if len(synsets) > 0:\n",
        "              synset = synsets[0]\n",
        "              for l in synset.lemmas():\n",
        "                  if l.name() == token['lemma']:\n",
        "                      n_token = l.key()\n",
        "          if n_token is not None:\n",
        "            new_sentence.append(n_token)\n",
        "          else:\n",
        "            new_sentence.append(token['lemma']) # it may be words that are common on children vocabulary.\n",
        "    print(new_sentence)\n",
        "    f.write(\" \".join(new_sentence)+\"\\n\")\n",
        "    print()\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I got an owie from Titus like Marky got an owie from Titus .\n",
            "['i', 'get%2:40:00::', 'a', '[NOSENSE]', 'from', 'proper_noun', 'like', 'proper_noun', 'get%2:40:00::', 'a', '[NOSENSE]', 'from', 'proper_noun', '.']\n",
            "\n",
            "why does that cat do that ?\n",
            "['why', 'do%2:41:01::', 'that', 'cat%1:05:00::', 'do%2:41:01::', 'that', '?']\n",
            "\n",
            "because she because her do .\n",
            "['because', 'she', 'because', 'she', 'do%2:41:01::', '.']\n",
            "\n",
            "because her do ?\n",
            "['because', 'she', 'do%2:41:01::', '?']\n",
            "\n",
            "why does she do it Ross ?\n",
            "['why', 'do%2:41:01::', 'she', 'do%2:41:01::', 'it', 'proper_noun', '?']\n",
            "\n",
            "because her do .\n",
            "['because', 'she', 'do%2:41:01::', '.']\n",
            "\n",
            "is she mean ?\n",
            "['be%2:42:03::', 'she', 'mean%2:32:01::', '?']\n",
            "\n",
            "yes .\n",
            "['yes%1:10:00::', '.']\n",
            "\n",
            "is she mean ?\n",
            "['be%2:42:03::', 'she', 'mean%2:32:01::', '?']\n",
            "\n",
            "I don't like that cat .\n",
            "['i', 'do%2:41:01::', '[NOSENSE]', '[NOSENSE]', 'like', 'that', 'cat%1:05:00::', '.']\n",
            "\n",
            "why does she do it ?\n",
            "['why', 'do%2:41:01::', 'she', 'do%2:41:01::', 'it', '?']\n",
            "\n",
            "cause she do .\n",
            "['cause%1:10:00::', 'she', 'do%2:41:01::', '.']\n",
            "\n",
            "let's give her a spanking .\n",
            "['let%2:41:00::', 's', 'give%2:40:03::', 'she', 'a', 'spanking%1:04:00::', '.']\n",
            "\n",
            "okay .\n",
            "['okay%5:00:00:satisfactory:00', '.']\n",
            "\n",
            "no no no .\n",
            "['no%1:10:00::', 'no%4:02:02::', 'no%4:02:02::', '.']\n",
            "\n",
            "no let's not .\n",
            "['no%4:02:02::', 'let%2:41:00::', 's', 'not%4:02:00::', '.']\n",
            "\n",
            "let's try to talk to her okay .\n",
            "['let%2:41:00::', 's', 'try%2:41:00::', 'to', 'talk%2:32:01::', 'to', 'she', 'okay%5:00:00:satisfactory:00', '.']\n",
            "\n",
            "why ?\n",
            "['why', '?']\n",
            "\n",
            "I'll try to talk to her .\n",
            "['i', '[NOSENSE]', 'try%2:41:00::', 'to', 'talk%2:32:01::', 'to', 'she', '.']\n",
            "\n",
            "owies hurt .\n",
            "['[NOSENSE]', 'hurt%2:39:00::', '.']\n",
            "\n",
            "I don't like owies .\n",
            "['i', 'do%2:41:01::', '[NOSENSE]', '[NOSENSE]', 'like', '[NOSENSE]', '.']\n",
            "\n",
            "he must have learned that at preschool because we don't use owies we don't talk about owies .\n",
            "['he', 'have%2:40:00::', 'learn%2:31:01::', 'that', 'at', 'preschool%1:14:00::', 'because', 'we', 'do%2:41:01::', '[NOSENSE]', 't', 'use%1:04:00::', '[NOSENSE]', 'we', 'do%2:41:01::', '[NOSENSE]', '[NOSENSE]', 'talk%1:10:00::', 'about%4:02:00::', '[NOSENSE]', '.']\n",
            "\n",
            "this is excellent Ross .\n",
            "['this', 'be%2:42:03::', 'excellent%5:00:00:superior:02', 'proper_noun', '.']\n",
            "\n",
            "what else do you wanna eat ?\n",
            "['what', 'do%2:41:01::', 'you', 'eat%2:34:00::', '?']\n",
            "\n",
            "I wanna eat some more\n",
            "['i', 'eat%2:34:00::', 'some']\n",
            "\n",
            "he wants some coq_au_vin juice .\n",
            "['he', 'want%2:37:00::', 'some', 'juice%1:13:00::', '.']\n",
            "\n",
            "no .\n",
            "['no%1:10:00::', '.']\n",
            "\n",
            "can I have some chicken off of that ?\n",
            "['can', 'i', 'have%2:40:00::', 'some', 'chicken%1:13:00::', 'off%4:02:03::', 'of', 'that', '?']\n",
            "\n",
            "uh hm .\n",
            "['hm%1:23:00::', '.']\n",
            "\n",
            "I'll serve you .\n",
            "['i', '[NOSENSE]', 'serve%2:41:02::', 'you', '.']\n",
            "\n",
            "can I have some more chicken ?\n",
            "['can', 'i', 'have%2:40:00::', 'some', 'many%3:00:00::', 'chicken%1:13:00::', '?']\n",
            "\n",
            "more chicken ?\n",
            "['more%4:02:00::', 'chicken%1:13:00::', '?']\n",
            "\n",
            "yeah .\n",
            "['.']\n",
            "\n",
            "Ross gets a nice piece here mom .\n",
            "['proper_noun', 'get%2:40:00::', 'a', 'nice%3:00:00::', 'piece%1:06:05::', 'here%4:02:00::', 'mom%1:18:00::', '.']\n",
            "\n",
            "uhuh .\n",
            "['.']\n",
            "\n",
            "he does .\n",
            "['he', 'do%2:41:01::', '.']\n",
            "\n",
            "and momma gets that nice piece .\n",
            "['and', 'momma%1:18:00::', 'get%2:40:00::', 'that', 'nice%3:00:00::', 'piece%1:06:05::', '.']\n",
            "\n",
            "and this big piece back here .\n",
            "['and', 'this', 'big%3:00:01::', 'piece%1:06:05::', 'back%4:02:04::', 'here%4:02:00::', '.']\n",
            "\n",
            "thank_you .\n",
            "['thank_you%1:10:00::', '.']\n",
            "\n",
            "very good chicken .\n",
            "['very%4:02:00::', 'good%3:00:01::', 'chicken%1:13:00::', '.']\n",
            "\n",
            "mhm .\n",
            "['[NOSENSE]', '.']\n",
            "\n",
            "thank_you .\n",
            "['thank_you%1:10:00::', '.']\n",
            "\n",
            "you're welcome Mother .\n",
            "['you', '[NOSENSE]', 'welcome%3:00:00::', 'mother%1:18:00::', '.']\n",
            "\n",
            "Mary said it was .\n",
            "['mary%1:18:00::', 'say%2:32:00::', 'it', 'be%2:42:03::', '.']\n",
            "\n",
            "no the bird says\n",
            "['no%1:10:00::', 'the', 'bird%1:05:00::', 'say%2:32:00::']\n",
            "\n",
            "coo coo .\n",
            "['coo%1:11:00::', 'coo%1:11:00::', '.']\n",
            "\n",
            "what is the bird doing ?\n",
            "['what', 'be%2:42:06::', 'the', 'bird%1:05:00::', 'do%2:41:01::', '?']\n",
            "\n",
            "I said\n",
            "['i', 'say%2:32:00::']\n",
            "\n",
            "the daddy bird flew away and the baby bird flew away and the mommy bird flew away .\n",
            "['the', 'daddy%1:18:00::', 'bird%1:05:00::', 'fly%2:38:00::', 'away%4:02:00::', 'and', 'the', 'baby%1:18:00::', 'bird%1:05:00::', 'fly%2:38:00::', 'away%4:02:00::', 'and', 'the', 'bird%1:05:00::', 'fly%2:38:00::', 'away%4:02:00::', '.']\n",
            "\n",
            "will you read the bear's Christmas ?\n",
            "['will%2:32:00::', 'you', 'read%2:31:00::', 'the', 'bear%1:05:00::', 's', 'christmas%1:28:00::', '?']\n",
            "\n",
            "mhm .\n",
            "['[NOSENSE]', '.']\n",
            "\n",
            "the bear's christmas ?\n",
            "['the', 'bear%1:05:00::', 's', '[NOSENSE]', '?']\n",
            "\n",
            "yeah .\n",
            "['.']\n",
            "\n",
            "you mean the Bearinstein Bear's ?\n",
            "['you', 'mean%2:32:01::', 'the', 'proper_noun', 'bear%1:05:00::', 's', '?']\n",
            "\n",
            "I want xxx the bear's christmas .\n",
            "['i', 'want%2:37:00::', 'the', 'bear%1:05:00::', '[NOSENSE]', '.']\n",
            "\n",
            "mhm .\n",
            "['[NOSENSE]', '.']\n",
            "\n",
            "can I have chicken ?\n",
            "['can', 'i', 'have%2:40:00::', 'chicken%1:13:00::', '?']\n",
            "\n",
            "mhm .\n",
            "['[NOSENSE]', '.']\n",
            "\n",
            "can I have some more chicken ?\n",
            "['can', 'i', 'have%2:40:00::', 'some', 'many%3:00:00::', 'chicken%1:13:00::', '?']\n",
            "\n",
            "yeah you want a good piece ?\n",
            "['you', 'want%2:37:00::', 'a', 'good%3:00:01::', 'piece%1:10:01::', '?']\n",
            "\n",
            "yeah .\n",
            "['.']\n",
            "\n",
            "here you go .\n",
            "['here%4:02:02::', 'you', 'go%2:38:00::', '.']\n",
            "\n",
            "that's a bad piece .\n",
            "['that', 'a', 'bad%3:00:00::', 'piece%1:06:05::', '.']\n",
            "\n",
            "wait a second wait a second I'll take the bad part off .\n",
            "['wait%2:42:01::', 'a', 'second%5:00:00:ordinal:00', 'wait%1:28:00::', 'a', 'second%1:28:00::', 'i', '[NOSENSE]', 'take%2:31:01::', 'the', 'bad%3:00:00::', 'part%1:24:00::', 'off%4:02:03::', '.']\n",
            "\n",
            "there it's all good .\n",
            "['there%4:02:00::', 'it', 's', 'all', 'good%3:00:01::', '.']\n",
            "\n",
            "but I don't want that .\n",
            "['but', 'i', 'do%2:41:01::', '[NOSENSE]', '[NOSENSE]', 'want%2:37:00::', 'that', '.']\n",
            "\n",
            "want want the pork ?\n",
            "['want%2:37:00::', 'want%2:37:00::', 'the', 'pork%1:13:00::', '?']\n",
            "\n",
            "I don't want that .\n",
            "['i', 'do%2:41:01::', '[NOSENSE]', '[NOSENSE]', 'want%2:37:00::', 'that', '.']\n",
            "\n",
            "I just want the other chicken .\n",
            "['i', 'just%4:02:00::', 'want%2:37:00::', 'the', 'other%3:00:00::', 'chicken%1:13:00::', '.']\n",
            "\n",
            "I just want that good piece .\n",
            "['i', 'just%4:02:00::', 'want%2:37:00::', 'that', 'good%3:00:01::', 'piece%1:11:00::', '.']\n",
            "\n",
            "that little piece right here .\n",
            "['that', 'little%3:00:01::', 'piece%1:06:05::', 'right%1:21:00::', 'here%4:02:00::', '.']\n",
            "\n",
            "yeah .\n",
            "['.']\n",
            "\n",
            "okay .\n",
            "['okay%5:00:00:satisfactory:00', '.']\n",
            "\n",
            "I like that piece .\n",
            "['i', 'like', 'that', 'piece%1:06:00::', '.']\n",
            "\n",
            "mhm .\n",
            "['[NOSENSE]', '.']\n",
            "\n",
            "okay sit down and you've got a real good piece on your plate a real good piece .\n",
            "['sit_down%2:38:00::', 'and', 'you', '[NOSENSE]', 'get%2:40:00::', 'a', 'real%3:00:02::', 'good%5:00:00:advantageous:00', 'piece%1:06:05::', 'on%4:02:00::', 'your', 'plate%1:06:04::', 'a', 'real%3:00:02::', 'good%5:00:00:advantageous:00', 'piece%1:17:00::', '.']\n",
            "\n",
            "in fact one of the best pieces is the one on your plate .\n",
            "['in_fact%4:02:00::', 'one%1:23:00::', 'of', 'the', 'good%5:00:00:opportune:00', 'piece%1:06:00::', 'be%2:42:06::', 'the', 'one%1:23:00::', 'on%4:02:00::', 'your', 'plate%1:06:04::', '.']\n",
            "\n",
            "it may be one of the best pieces on the whole chicken .\n",
            "['it', 'be%2:42:06::', 'one%1:23:00::', 'of', 'the', 'good%5:00:00:advantageous:00', 'piece%1:06:05::', 'on_the_whole%4:02:00::', 'chicken%1:13:00::', '.']\n",
            "\n",
            "Marky is all pink checked .\n",
            "['proper_noun', 'be%2:42:03::', 'all', 'pink%5:00:00:chromatic:00', 'check%2:31:00::', '.']\n",
            "\n",
            "Marky is awake now .\n",
            "['proper_noun', 'be%2:42:03::', 'now%4:02:05::', '.']\n",
            "\n",
            "his sentence made more sense than mine .\n",
            "['his', 'sentence%1:10:00::', 'make%2:30:00::', 'many%3:00:00::', 'sense%1:09:05::', 'than', 'mine%1:06:00::', '.']\n",
            "\n",
            "you hurt my peepeesh .\n",
            "['you', 'hurt%2:30:04::', 'my', '[NOSENSE]', '.']\n",
            "\n",
            "I didn't know .\n",
            "['i', 'do%2:41:01::', '[NOSENSE]', '[NOSENSE]', 'know%2:31:01::', '.']\n",
            "\n",
            "you didn't know what you're doing .\n",
            "['you', 'do%2:41:01::', '[NOSENSE]', '[NOSENSE]', 'know%2:31:01::', 'what', 'you', '[NOSENSE]', 'do%2:41:01::', '.']\n",
            "\n",
            "is that right ?\n",
            "['be%2:42:03::', 'that', 'right%1:15:00::', '?']\n",
            "\n",
            "what's happening now ?\n",
            "['what', 'happen%2:30:00::', 'now%4:02:05::', '?']\n",
            "\n",
            "I'm xxx you .\n",
            "['i', 'm%1:23:00::', '[NOSENSE]', 'you', '.']\n",
            "\n",
            "are you going to eat anymore cake ?\n",
            "['be%2:42:03::', 'you', 'go_to%2:42:00::', 'eat%2:34:00::', 'anymore%4:02:01::', 'cake%1:06:00::', '?']\n",
            "\n",
            "no .\n",
            "['no%1:10:00::', '.']\n",
            "\n",
            "your finished ?\n",
            "['your', 'finish%2:30:02::', '?']\n",
            "\n",
            "yeah .\n",
            "['.']\n",
            "\n",
            "okay we'll clean off your mouth and your hands ?\n",
            "['okay%5:00:00:satisfactory:00', 'we', 'clean%2:35:00::', 'your', 'mouth%1:08:01::', 'and', 'your', 'hand%1:08:00::', '?']\n",
            "\n",
            "hm no .\n",
            "['hm%1:23:00::', 'no%1:10:00::', '.']\n",
            "\n",
            "sticky ?\n",
            "['sticky%5:00:00:adhesive:00', '?']\n",
            "\n",
            "a little sticky ?\n",
            "['a', 'little%3:00:01::', 'sticky%5:00:00:adhesive:00', '?']\n",
            "\n",
            "nope .\n",
            "['[NOSENSE]', '.']\n",
            "\n",
            "nope ?\n",
            "['[NOSENSE]', '?']\n",
            "\n",
            "that's a little sticky .\n",
            "['that', 's', 'a', 'little%3:00:01::', 'sticky%5:00:00:adhesive:00', '.']\n",
            "\n",
            "and your mouth .\n",
            "['and', 'your', 'mouth%1:08:01::', '.']\n",
            "\n",
            "nope .\n",
            "['[NOSENSE]', '.']\n",
            "\n",
            "yep your mouth is dirty .\n",
            "['[NOSENSE]', 'your', 'mouth%1:08:01::', 'be%2:42:03::', 'dirty%3:00:01::', '.']\n",
            "\n",
            "yes it is .\n",
            "['yes%1:10:00::', 'it', 'be%2:42:03::', '.']\n",
            "\n",
            "yes it is I can see it .\n",
            "['yes%1:10:00::', 'it', 'be%2:42:06::', 'i', 'can', 'see%2:39:00::', 'it', '.']\n",
            "\n",
            "it's not so bad but we'll clean it okay .\n",
            "['it', 's', 'not%4:02:00::', 'so%4:02:02::', 'bad%3:00:00::', 'but', 'we', 'clean%2:35:00::', 'it', 'okay%5:00:00:satisfactory:00', '.']\n",
            "\n",
            "oh Mom that's so nice of you .\n",
            "['mom%1:18:00::', 'that', 's', 'so%4:02:02::', 'nice%3:00:00::', 'of', 'you', '.']\n",
            "\n",
            "okay you're finished right Ross ?\n",
            "['okay%5:00:00:satisfactory:00', 'you', '[NOSENSE]', 'finish%2:30:02::', 'right%4:02:08::', 'proper_noun', '?']\n",
            "\n",
            "very good cake mom .\n",
            "['very%4:02:00::', 'good%3:00:01::', 'cake%1:06:00::', 'mom%1:18:00::', '.']\n",
            "\n",
            "excellent frosting .\n",
            "['excellent%5:00:00:superior:02', 'frosting%1:13:00::', '.']\n",
            "\n",
            "excellent frosting .\n",
            "['excellent%5:00:00:superior:02', 'frosting%1:13:00::', '.']\n",
            "\n",
            "excellent frosting .\n",
            "['excellent%5:00:00:superior:02', 'frosting%1:13:00::', '.']\n",
            "\n",
            "super moist .\n",
            "['super%5:00:00:superior:02', 'moist%5:00:00:wet:01', '.']\n",
            "\n",
            "it's excellent frosting because it's homemade .\n",
            "['it', 's', 'excellent%5:00:00:superior:02', 'frosting%1:13:00::', 'because', 'it', 's', '[NOSENSE]', '.']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}